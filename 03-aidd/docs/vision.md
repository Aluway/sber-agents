# Техническое видение проекта

## 1. Технологии

### Обязательные технологии

**Язык программирования и инструменты:**
- **Python** (>=3.10) - основной язык разработки
- **uv** - управление зависимостями Python-проекта

**Библиотеки:**
- **python-dotenv** - для загрузки переменных окружения из .env файла
- **openai** (OpenAI client) - для работы с LLM через провайдер OpenRouter API
- **aiogram** - для интеграции с Telegram Bot API через метод polling

**Система сборки:**
- **Make** - для автоматизации команд сборки и запуска проекта

### Принципы выбора

Все технологии выбраны с учетом требований максимальной простоты (KISS, YAGNI):
- Стандартные и проверенные решения
- Минимальный набор зависимостей
- Простота настройки и разработки
- Быстрый старт для проверки идеи

---

## 2. Принципы разработки

### Основные принципы

**KISS (Keep It Simple, Stupid):**
- Максимальная простота архитектуры и кода
- Избегание преждевременной оптимизации
- Понятная структура проекта
- Прямолинейная реализация без сложных абстракций

**YAGNI (You Aren't Gonna Need It):**
- Реализация только необходимого функционала для проверки идеи
- Отказ от "на будущее" архитектурных решений
- Фокус на MVP (Minimum Viable Product)

**Pragmatic Development:**
- Итеративная разработка
- Приоритет на работоспособность над красотой кода
- Быстрая проверка гипотез

---

## 3. Структура проекта

### Файловая структура

```
03-aidd/
├── src/
│   └── bot.py              # Основной файл бота (вся логика в одном файле)
├── docs/                   # Документация
│   ├── idea.md            # Концепция проекта
│   └── vision.md          # Техническое видение
├── .env                   # Переменные окружения (не в git)
├── .env.example           # Шаблон .env файла
├── .gitignore             # Git ignore правила
├── pyproject.toml         # Конфигурация проекта и зависимости
├── uv.lock                # Lock файл зависимостей (генерируется автоматически)
├── Makefile               # Команды для сборки и запуска
└── README.md              # Инструкция по использованию
```

### Принцип организации

**Монолитный подход:**
- Вся логика бота в одном файле `src/bot.py`
- Нет разделения на модули, сервисы, слои
- Максимально простая структура для быстрого старта
- Легко понять, изменить и отладить

**Описание файлов:**
- `src/bot.py` - Telegram-бот на aiogram с интеграцией LLM через OpenAI client
- `pyproject.toml` - конфигурация Python-проекта и список зависимостей
- `Makefile` - автоматизация команд (setup, run, clean)
- `.env` - хранение секретных данных (API ключи)

---

## 4. Архитектура проекта

### Упрощенная архитектура

```
┌─────────────┐
│   User      │
└─────┬───────┘
      │ Отправляет сообщение
      ↓
┌─────────────────────────────────────┐
│      Telegram API                   │
└─────┬───────────────────────────────┘
      │ Получает сообщение через polling
      ↓
┌─────────────────────────────────────┐
│   Bot (aiogram)                     │
│   - Обрабатывает сообщения          │
│   - Управляет историей диалога      │
│   - Формирует запросы к LLM         │
└─────┬───────────────────────────────┘
      │ Отправляет запрос с историей
      ↓
┌─────────────────────────────────────┐
│   OpenRouter API                    │
│   (OpenAI client)                   │
└─────┬───────────────────────────────┘
      │ Возвращает ответ от LLM
      ↓
┌─────────────────────────────────────┐
│   Bot                               │
│   - Получает ответ от LLM           │
│   - Сохраняет в историю диалога     │
│   - Отправляет ответ пользователю   │
└─────┬───────────────────────────────┘
      │
      ↓
┌─────────────┐
│   User      │
└─────────────┘
```

### Компоненты

**1. Telegram Bot Handler (aiogram):**
- Прием сообщений от пользователя через polling
- Передача сообщений в LLM-обработчик
- Отправка ответов обратно пользователю

**2. LLM Client (OpenAI):**
- Инициализация клиента для работы с OpenRouter API
- Формирование запросов с учетом истории диалога
- Получение ответов от LLM

**3. Conversation Manager:**
- Хранение истории диалога в памяти (in-memory)
- Добавление системного промпта финансового советника
- Управление контекстом разговора

**4. Configuration:**
- Загрузка переменных окружения (.env)
- API ключи для Telegram и OpenRouter
- Настройки модели LLM

### Принципы архитектуры

**Простота:**
- Вся логика в одном классе/файле
- Нет разделения на слои и сервисы
- In-memory хранение (без БД)
- Нет кеширования, очередей, воркеров

**Прямолинейность:**
- Каждое сообщение обрабатывается синхронно
- Нет асинхронных фоновых задач
- Простой flow: получение → обработка → ответ

---

## 5. Модель данных

### Структуры данных

**Сообщение пользователя:**
```python
{
    "role": "user",
    "content": "Как накопить на квартиру?"
}
```

**Сообщение ассистента:**
```python
{
    "role": "assistant", 
    "content": "Для накопления на квартиру рекомендую..."
}
```

**Системный промпт:**
```python
{
    "role": "system",
    "content": "Ты — профессиональный финансовый советник..."
}
```

### История диалога

**Формат (OpenAI messages API):**
```python
conversation_history = [
    {"role": "system", "content": "Ты — финансовый советник..."},
    {"role": "user", "content": "Привет"},
    {"role": "assistant", "content": "Привет! Как я могу помочь?"},
    {"role": "user", "content": "Как накопить на квартиру?"},
    {"role": "assistant", "content": "Рекомендую..."}
]
```

### Хранение данных

**In-Memory (RAM):**
- История диалога хранится в памяти процесса
- При перезапуске бота история теряется
- Максимальная простота без БД
- Каждый пользователь = одна история (для MVP)

**Ограничения:**
- Не сохраняется между сессиями
- Нет multi-user поддержки на уровне истории
- Нет персистентного хранилища

---

## 6. Работа с LLM

### Конфигурация

**Провайдер:** OpenRouter (openrouter.ai)
- Агрегатор различных LLM моделей
- Единый API-интерфейс
- Доступ к OpenAI, Anthropic, Google и другим моделям

**Модель:** Настраивается через переменные окружения
- По умолчанию: `openai/gpt-3.5-turbo` (баланс качества и стоимости)
- Можно изменить на любую доступную модель через OpenRouter

**API клиент:** OpenAI Python client
- Стандартный интерфейс
- Работает с OpenRouter через custom base_url
- Поддержка chat completions API

### Процесс работы с LLM

**1. Инициализация клиента:**
```python
client = OpenAI(
    api_key=OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1"
)
```

**2. Формирование запроса:**
- История диалога передается целиком
- Системный промпт включает роль финансового советника
- Нет дополнительных параметров (temperature, top_p и т.д.)

**3. Отправка запроса:**
```python
response = client.chat.completions.create(
    model=model_name,
    messages=conversation_history
)
```

**4. Получение ответа:**
- Извлечение content из response
- Сохранение в историю диалога
- Обработка возможных ошибок

### Системный промпт

**Роль:** Финансовый советник
**Стиль:** Вежливый, профессиональный, конкретный
**Функции:** 
- Давать советы по финансам
- Помогать с накоплениями
- Отвечать на вопросы по планированию бюджета

**Пример:**
```
Ты — профессиональный финансовый советник. 
Твоя задача — помогать пользователям с финансовыми вопросами, 
планированием бюджета и накоплениями. Отвечай кратко, по делу и дружелюбно.
```

### Ограничения

**Контекстное окно:**
- Зависит от выбранной модели
- Для GPT-3.5-turbo: ~4000 токенов
- При переполнении: обрезка старых сообщений

**Стоимость:**
- Каждый запрос расходует токены
- Необходим мониторинг usage
- OpenRouter показывает стоимость запроса

---

## 7. Сценарии работы

### Базовый сценарий: Вопрос-ответ

**Входные данные:**
- Пользователь отправляет текст в Telegram

**Шаги:**
1. Бот получает сообщение через aiogram polling
2. Добавляет сообщение в историю диалога
3. Формирует запрос к OpenRouter API
4. Получает ответ от LLM
5. Добавляет ответ в историю диалога
6. Отправляет ответ пользователю в Telegram

**Результат:** Пользователь получает ответ от финансового советника

### Сценарий: Диалог с контекстом

**Описание:** Пользователь задает несколько связанных вопросов

**Особенности:**
- История диалога накапливается
- LLM помнит предыдущие сообщения
- Возможность уточнений и продолжения темы
- Контекст сохраняется в пределах запущенного процесса

**Пример:**
```
Пользователь: Как накопить на квартиру?
Ассистент: Рекомендую откладывать 30% от дохода...

Пользователь: А если у меня низкая зарплата?
Ассистент: В таком случае начните с малого - 10-15%...
```

### Сценарий: Обработка ошибок

**Типичные ошибки:**
- Нет ответа от OpenRouter API (timeout, network error)
- Превышен лимит токенов
- Неверный API ключ

**Обработка:**
- Логирование ошибки
- Отправка сообщения пользователю с объяснением
- Сохранение работоспособности бота

---

## 8. Подход к конфигурированию

### Источники конфигурации

**1. Переменные окружения (.env файл):**
- Хранение секретных данных (API ключи)
- Настройки подключения
- Управление конфигурацией без изменения кода

**2. Константы в коде:**
- Системный промпт
- Настройки по умолчанию
- Логика работы приложения

### Структура .env файла

```env
# Telegram Bot API
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# OpenRouter API
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# LLM Model
MODEL_NAME=openai/gpt-3.5-turbo
```

### Загрузка конфигурации

**Библиотека:** python-dotenv
```python
from dotenv import load_dotenv
import os

load_dotenv()  # Загружает .env файл

api_key = os.getenv("OPENROUTER_API_KEY")
model = os.getenv("MODEL_NAME", "openai/gpt-3.5-turbo")  # с дефолтным значением
```

### Принципы

**Безопасность:**
- Все секретные данные в .env (не в коде)
- .env файл в .gitignore
- .env.example как шаблон

**Простота:**
- Минимум параметров
- Понятные названия переменных
- Разумные значения по умолчанию

**Прозрачность:**
- Все настройки видны в одном файле
- Легко изменить без изменения кода

---

## 9. Подход к логгированию

### Минималистичный подход

**Встроенное логирование Python:**
- Используем стандартную библиотеку `logging`
- Без дополнительных библиотек или настройки
- Простой вывод в консоль

### Уровни логов

**INFO** - важные события:
- Запуск бота
- Получение сообщения от пользователя
- Успешный ответ от LLM

**ERROR** - ошибки:
- Ошибки подключения к OpenRouter
- Ошибки обработки сообщений
- Критические сбои

**DEBUG** - детальная информация:
- Для разработки и отладки
- Можно отключить в продакшене

### Формат логов

**Простой формат:**
```
INFO:Bot started
INFO:Received message from user
INFO:Sent response to user
ERROR:Failed to connect to OpenRouter API
```

**Структура:**
- Временная метка (опционально)
- Уровень лога
- Сообщение

### Практика логгирования

**Что логировать:**
- Старт/остановка бота
- Ошибки API запросов
- Важные события (для отладки)

**Чего избегать:**
- Логирование каждого сообщения (приватность)
- Избыточное логирование
- Сложные форматы

**Безопасность:**
- Не логируем API ключи
- Не логируем полные истории диалогов
- Уважение приватности пользователей

### Реализация

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(message)s'
)

logger = logging.getLogger(__name__)
logger.info("Bot started")
logger.error("Connection failed")
```

---

## Резюме

### Ключевые решения

1. **Максимальная простота:** Вся логика в одном файле, минимум абстракций
2. **Быстрый старт:** Минимум зависимостей, простое развертывание
3. **Фокус на MVP:** Только необходимая функциональность для проверки идеи
4. **Проверенные технологии:** Стандартные инструменты и библиотеки
5. **In-memory хранение:** Без БД для упрощения архитектуры

### Следующие шаги

1. Создать структуру проекта
2. Настроить зависимости (pyproject.toml)
3. Реализовать бота (src/bot.py)
4. Создать конфигурационные файлы
5. Протестировать базовые сценарии

### Гибкость для развития

При успешной проверке идеи можно добавить:
- Хранение истории в БД
- Multi-user поддержка
- Админ панель
- Дополнительные фичи

Но сейчас - только самое необходимое!