{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/langchain.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/image_rag.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain. Naive RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/image_langchain.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Settings\n",
    "\n",
    "Р’Р°Рј РЅСѓР¶РЅРѕ Р±СѓРґРµС‚ СѓСЃС‚Р°РЅРѕРІРёС‚СЊ РЅРµСЃРєРѕР»СЊРєРѕ РїР°РєРµС‚РѕРІ Рё СѓСЃС‚Р°РЅРѕРІРёС‚СЊ РІР°С€ OpenAI API РєР»СЋС‡ РєР°Рє РїРµСЂРµРјРµРЅРЅСѓСЋ РѕРєСЂСѓР¶РµРЅРёСЏ СЃ РёРјРµРЅРµРј `OPENAI_API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-chroma beautifulsoup4\n",
    "%pip install -qU langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUN_INSTALL: /Users/gazebo/.bun\n",
      "COMMAND_MODE: unix2003\n",
      "CONDA_DEFAULT_ENV: base\n",
      "CONDA_EXE: /opt/homebrew/Caskroom/miniconda/base/bin/conda\n",
      "CONDA_PREFIX: /opt/homebrew/Caskroom/miniconda/base\n",
      "CONDA_PROMPT_MODIFIER: (base) \n",
      "CONDA_PYTHON_EXE: /opt/homebrew/Caskroom/miniconda/base/bin/python\n",
      "CONDA_SHLVL: 1\n",
      "CURSOR_TRACE_ID: 6784bebb500d4bb78e063b268a047591\n",
      "HOME: /Users/gazebo\n",
      "HOMEBREW_CELLAR: /opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX: /opt/homebrew\n",
      "HOMEBREW_REPOSITORY: /opt/homebrew\n",
      "INFOPATH: /opt/homebrew/share/info:\n",
      "LOGNAME: gazebo\n",
      "MallocNanoZone: 0\n",
      "OLDPWD: /\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP: undefined\n",
      "PATH: /Users/gazebo/work/smirnoff_ai/courses/llmstart-02082025/notebooks/.venv_notebook_demo/bin:/Users/gazebo/.local/bin:/Users/gazebo/.bun/bin:/Users/gazebo/.local/bin:/opt/homebrew/Caskroom/miniconda/base/bin:/opt/homebrew/Caskroom/miniconda/base/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/gazebo/.lmstudio/bin\n",
      "PWD: /\n",
      "SHELL: /bin/zsh\n",
      "SHLVL: 1\n",
      "SSH_AUTH_SOCK: /private/tmp/com.apple.launchd.MhhWOgqeUx/Listeners\n",
      "TMPDIR: /var/folders/_k/7q0q098s44bc8pbczmplf_8h0000gn/T/\n",
      "USER: gazebo\n",
      "VSCODE_CODE_CACHE_PATH: /Users/gazebo/Library/Application Support/Cursor/CachedData/505046dcfad2acda3d066e32b7cd8b6e2dc1fdc0\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE: extensionHost\n",
      "VSCODE_CWD: /\n",
      "VSCODE_ESM_ENTRYPOINT: vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS: true\n",
      "VSCODE_IPC_HOOK: /Users/gazebo/Library/Application Support/Cursor/2.0.-main.sock\n",
      "VSCODE_NLS_CONFIG: {\"userLocale\":\"ru\",\"osLocale\":\"ru-ru\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/Applications/Cursor.app/Contents/Resources/app/out/nls.messages.json\",\"locale\":\"ru\",\"availableLanguages\":{}}\n",
      "VSCODE_PID: 1517\n",
      "VSCODE_PROCESS_TITLE: extension-host  [3-3]\n",
      "XPC_FLAGS: 0x0\n",
      "XPC_SERVICE_NAME: 0\n",
      "_: /Users/gazebo/work/smirnoff_ai/courses/llmstart-02082025/notebooks/.venv_notebook_demo/bin/python\n",
      "__CFBundleIdentifier: com.todesktop.230313mzl4w4u92\n",
      "__CF_USER_TEXT_ENCODING: 0x1F5:0x7:0x31\n",
      "ELECTRON_RUN_AS_NODE: 1\n",
      "PYTHONUNBUFFERED: 1\n",
      "PYTHONIOENCODING: utf-8\n",
      "CURSOR_SPAWN_CHAIN: ms-python.python|ms-python.python|ms-toolsai.jupyter\n",
      "VIRTUAL_ENV: /Users/gazebo/work/smirnoff_ai/courses/llmstart-02082025/notebooks/.venv_notebook_demo\n",
      "CURSOR_SPAWNED_BY_EXTENSION_ID: ms-toolsai.jupyter\n",
      "PS1: (.venv_notebook_demo) \n",
      "VIRTUAL_ENV_PROMPT: (.venv_notebook_demo) \n",
      "LC_CTYPE: C.UTF-8\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING: 1\n",
      "PYTHON_FROZEN_MODULES: on\n",
      "PYDEVD_USE_FRAME_EVAL: NO\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "FORCE_COLOR: 1\n",
      "CLICOLOR_FORCE: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://matplotlib_inline.backend_inline\n",
      "OPENAI_API_KEY: your-openai-api-key-here\n",
      "OPENAI_BASE_URL: https://openrouter.ai/api/v1\n",
      "LANGCHAIN_TRACING_V2: true\n",
      "LANGCHAIN_ENDPOINT: https://api.smith.langchain.com\n",
      "LANGCHAIN_API_KEY: your-langchain-api-key-here\n",
      "LANGCHAIN_PROJECT: sberagents_live\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print all environment variables\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/image_vectorstore.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Р—Р°РіСЂСѓР·РєР° РґРѕРєСѓРјРµРЅС‚РѕРІ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader\n",
    "Р’РѕСЃРїРѕР»СЊР·СѓРµРјСЃСЏ PyPDFLoader РґР»СЏ Р·Р°РіСЂСѓР·РєРё РґРѕРєСѓРјРµРЅС‚Р°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    file_path = \"./documents/smirnoff_ai.pdf\",\n",
    "    mode = \"page\",\n",
    "    extraction_mode = \"plain\"\n",
    "     # headers = None\n",
    "    # password = None,\n",
    "    # pages_delimiter = \"\",\n",
    "    # extract_images = True,\n",
    "    # images_parser = RapidOCRBlobParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РўРµРїРµСЂСЊ РїСЂРѕС‡РёС‚Р°РµРј РєР°Р¶РґСѓСЋ СЃС‚СЂР°РЅРёС†Сѓ РґРѕРєСѓРјРµРЅС‚Р° Рё СЃРѕС…СЂР°РЅРёРј РІ СЃРїРёСЃРѕРє:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pages = []\n",
    "for page in loader.load():\n",
    "    pages.append(page) \n",
    "       \n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р”Р°РІР°Р№С‚Рµ РїРѕСЃРјРѕС‚СЂРёРј РЅР° РїРµСЂРІСѓСЋ СЃС‚СЂР°РЅРёС†Сѓ РґРѕРєСѓРјРµРЅС‚Р°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Skia/PDF m136 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'SMIRNOFF_AI. РџСЂРѕС„РёР»СЊ СЃ РїРѕСЂС‚С„РѕР»РёРѕ', 'source': './documents/smirnoff_ai.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "РџСЂРѕС„РµСЃСЃРёРѕРЅР°Р»СЊРЅР°СЏ  СЂР°Р·СЂР°Р±РѕС‚РєР°  РР-СЂРµС€РµРЅРёР№  РґР»СЏ  Р±РёР·РЅРµСЃР°  \n",
      "РџСЂРѕС„РµСЃСЃРёРѕРЅР°Р»СЊРЅР°СЏ  СЂР°Р·СЂР°Р±РѕС‚РєР°  Рё  РІРЅРµРґСЂРµРЅРёРµ  СЃРёСЃС‚РµРј  РёСЃРєСѓСЃСЃС‚РІРµРЅРЅРѕРіРѕ  РёРЅС‚РµР»Р»РµРєС‚Р°,  РР-Р°СЃСЃРёСЃС‚РµРЅС‚РѕРІ,  РР-Р°РіРµРЅС‚РѕРІ,  РР-Р±РѕС‚РѕРІ  Рё  РґСЂСѓРіРёС…  СЂРµС€РµРЅРёР№  РЅР°  Р±Р°Р·Рµ  РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ  РёСЃРєСѓСЃСЃС‚РІРµРЅРЅРѕРіРѕ  РёРЅС‚РµР»Р»РµРєС‚Р°  РґР»СЏ  С‡Р°СЃС‚РЅС‹С…  РєР»РёРµРЅС‚РѕРІ,  РјР°Р»РѕРіРѕ  Рё  СЃСЂРµРґРЅРµРіРѕ  Р±РёР·РЅРµСЃР°.  \n",
      "РЈРЎР›РЈР“Р вЂ”  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- СЂРµС€РµРЅРёР№/Р°РіРµРЅС‚РѕРІ/Р±РѕС‚РѕРІ  РґР»СЏ  Р°РІС‚РѕРјР°С‚РёР·Р°С†РёРё  Р±РёР·РЅРµСЃР°  вЂ”  РђСѓРґРёС‚  РїСЂРѕС†РµСЃСЃРѕРІ  Рё  СЂР°Р·СЂР°Р±РѕС‚РєР°  РґРѕСЂРѕР¶РЅРѕР№  РєР°СЂС‚С‹  РІРЅРµРґСЂРµРЅРёСЏ  AI  вЂ”  РљРѕРЅСЃР°Р»С‚РёРЅРі  РїРѕ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  Рё  РІРЅРµРґСЂРµРЅРёСЋ  AI  вЂ”  РћР±СѓС‡РµРЅРёРµ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  СЂРµС€РµРЅРёР№  РЅР°  Р±Р°Р·Рµ  РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ  РР  \n",
      "РљР›Р®Р§Р•Р’Р«Р•\n",
      " \n",
      "РљРћРњРџР•РўР•РќР¦РР\n",
      " \n",
      "Р\n",
      " \n",
      "РћРџР«Рў\n",
      " \n",
      "РР-Р°СЃСЃРёСЃС‚РµРЅС‚С‹  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- Р°СЃСЃРёСЃС‚РµРЅС‚РѕРІ,  РїРѕРІС‹С€Р°СЋС‰РёС…  СЌС„С„РµРєС‚РёРІРЅРѕСЃС‚СЊ  РІС‹РїРѕР»РЅРµРЅРёСЏ  СЂР°Р±РѕС‡РёС…  Р·Р°РґР°С‡  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ \n",
      "вЂ”  РР-Р°СЃСЃРёСЃС‚РµРЅС‚  СЃРѕС‚СЂСѓРґРЅРёРєР°  РјРµРґРёР°-Р°РіРµРЅС‚СЃС‚РІР°  MediaWise  вЂ”  РР-Р°СЃСЃРёСЃС‚РµРЅС‚  СЃР»СѓР¶Р±С‹  РїРѕРґРґРµСЂР¶РєРё  РІРёРґРµРѕС…РѕСЃС‚РёРЅРіР°  RUTUBE  вЂ”  РР-Р°СЃСЃРёСЃС‚РµРЅС‚  РѕРїРµСЂР°С‚РѕСЂР°  РњР¤Р¦  РЎРџР±  вЂ”  РР-Р°СЃСЃРёСЃС‚РµРЅС‚  Р¶СѓСЂРЅР°Р»РёСЃС‚Р°  Piter.tv  вЂ”  РР-Р°СЃСЃРёСЃС‚РµРЅС‚  РіР»Р°РІРЅРѕРіРѕ  Р°РіСЂРѕРЅРѕРјР°  \n",
      "РР-Р°РіРµРЅС‚С‹  \n",
      "Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- Р°РіРµРЅС‚РѕРІ,  РІС‹РїРѕР»РЅСЏСЋС‰РёС…  С„СѓРЅРєС†РёРё  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ,  С‡Р°СЃС‚РёС‡РЅРѕ  Рё  РїРѕР»РЅРѕСЃС‚СЊСЋ  Р·Р°РјРµС‰Р°СЏ  РёС… \n",
      "вЂ”  РљРѕСЂРїРѕСЂР°С‚РёРІРЅС‹Р№  HR- Р±РѕС‚  РґР»СЏ  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ  Р Р–Р”  вЂ”  РР-Р°РЅР°Р»РёС‚РёРє  СЃРёС‚СѓР°С†РёРѕРЅРЅРѕРіРѕ  С†РµРЅС‚СЂР°  РѕСЂРіР°РЅРѕРІ  РІР»Р°СЃС‚Рё  вЂ”  РР-РјРµРЅРµРґР¶РµСЂ  РїРѕ  РїСЂРѕРґР°Р¶Р°Рј  РёРЅС‚РµСЂРЅРµС‚-РјР°РіР°Р·РёРЅР°  Р·Р°РїС‡Р°СЃС‚РµР№  \n",
      "Р РµС€РµРЅРёСЏ  РЅР°  Р±Р°Р·Рµ  РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ  РР  \n",
      "Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- СЂРµС€РµРЅРёР№,  РїСЂРµРґРѕСЃС‚Р°РІР»СЏСЋС‰РёС…  РёРЅРЅРѕРІР°С†РёРѕРЅРЅС‹Рµ  РІРѕР·РјРѕР¶РЅРѕСЃС‚Рё \n",
      "вЂ”  РРЅС‚РµР»Р»РµРєС‚СѓР°Р»СЊРЅР°СЏ  СЃРёСЃС‚РµРјР°  РїРѕСЃС‚СЂРѕРµРЅРёСЏ  РєР°СЂСЊРµСЂРЅРѕР№  С‚СЂР°РµРєС‚РѕСЂРёРё  \n",
      "РљРѕРјРїР»РµРєСЃРЅС‹Рµ  СЃРёСЃС‚РµРјС‹  РР  \n",
      "Р Р°Р·СЂР°Р±РѕС‚РєР°  Рё  РІСЃС‚СЂР°РёРІР°РЅРёРµ  РР  РІ  СЃСѓС‰РµСЃС‚РІСѓСЋС‰РёРµ  СЃРёСЃС‚РµРјС‹  РґР»СЏ  СЂРµС€РµРЅРёСЏ  РєРѕРјРїР»РµРєСЃРЅС‹С…  Р·Р°РґР°С‡ \n",
      "вЂ”  РЎРёСЃС‚РµРјР°  РёРЅС‚РµР»Р»РµРєС‚СѓР°Р»СЊРЅРѕРіРѕ  РїРѕРёСЃРєР°  РІРёРґРµРѕ  РґР»СЏ  РІРёРґРµРѕС…РѕСЃС‚РёРЅРіР°  RUTUBE  вЂ”  РЎРёСЃС‚РµРјР°  СЂР°СЃРїРѕР·РЅР°РІР°РЅРёСЏ  СЂСѓРєРѕРїРёСЃРЅС‹С…  РёСЃС‚РѕСЂРёС‡РµСЃРєРёС…  РґРѕРєСѓРјРµРЅС‚РѕРІ  Р Р¤  вЂ”  РЎРёСЃС‚РµРјР°  С„Р°РєС‚РѕРіСЂР°С„РёС‡РµСЃРєРѕРіРѕ  Р°РЅР°Р»РёР·Р°  Р°СЂС…РёРІРЅС‹С…  РґРѕРєСѓРјРµРЅС‚РѕРІ\n",
      " \n",
      " \n",
      "РЎРјРёСЂРЅРѕРІ\n",
      " \n",
      "РЎРµСЂРіРµР№\n",
      ",\n",
      " \n",
      "Рє.С‚.РЅ.\n",
      " \n",
      "https://t.me/smirno п¬Ђ _ai \n",
      " \n",
      " \n",
      "Р¦РР¤Р Р«\n",
      " \n",
      "10+  Р›Р•Рў  Р’  Р РђР—Р РђР‘РћРўРљР•  РР  20+  Р›Р•Рў  Р’  Р РђР—Р РђР‘РћРўРљР•  РџРћ  10+  РџР РћР•РљРўРћР’  4   РџРћР‘Р•Р”Р«  РІ  РР-РҐРђРљРђРўРћРќРђРҐ  \n",
      "РЎРџР•Р¦РРђР›РР—РђР¦РРЇ\n",
      " \n",
      "  GenAI,  LLM,  VLM,  RAG,  NLP,  CV,  OCR  \n",
      "РЎРўР•Рљ\n",
      " \n",
      "РўР•РҐРќРћР›РћР“РР™\n",
      " \n",
      "  AI:  Python,  PyTorch,  Haystack,  LangChain,  LangGraph  Рё  РґСЂ.  Data:  MongoDB,  PostgreSQL,  Dremio,  Kafka  Рё  РґСЂ.  DevOps: Docker,  Ansible,  Kubernetes,  Airп¬‚ow  Рё  РґСЂ.  Cloud: Yandex  Cloud,  Terraform  Рё  РґСЂ.  \n",
      "РџР РћР¦Р•РЎРЎР«/РџР РђРљРўРРљР\n",
      " \n",
      "  Agile,  XP,  Microservices,  CI/CD,   IaC,  GitOps,  DocOps,  MLOps  \n",
      "РќРђР“Р РђР”Р«\n",
      " \n",
      "  РР-С…Р°РєР°С‚РѕРЅС‹  вЂњР¦РёС„СЂРѕРІРѕР№  РїСЂРѕСЂС‹РІвЂќ:  -  РњРµР¶РґСѓРЅР°СЂРѕРґРЅС‹Рµ  2024,  2023  -  Р РµРіРёРѕРЅР°Р»СЊРЅС‹Рµ  2024,  2023  РџР РћР¤- IT. РРЅРЅРѕРІР°С†РёСЏ  2023,2021  РџСЂРµРјРёСЏ  Р СѓРЅРµС‚Р°  2019  \n",
      "РЎР•Р РўРР¤РРљРђРўР«\n",
      " \n",
      "  Deep  Learning  School  (РњР¤РўР)  Yandex  Cloud,  Big  Data,  ICAgile,  LeanKanban,  SAFe  Certiп¬Ѓed\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р”Р°Р»РµРµ РјС‹ СЂР°Р·Р±РёРІР°РµРј РµРіРѕ РЅР° РјРµРЅСЊС€РёРµ chunks. Р’РѕСЃРїРѕР»СЊР·СѓРµРјСЃСЏ RecursiveCharacterTextSplitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore and embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "РўРµРїРµСЂСЊ Р·Р°РіСЂСѓР·РёРј РЅР°С€Рё С‡Р°РЅРєРё РІ **РІРµРєС‚РѕСЂРЅРѕРµ С…СЂР°РЅРёР»РёС‰Рµ**. РћРґРЅРѕРІСЂРµРјРµРЅРЅРѕ СЃ СЌС‚РёРј РґР»СЏ РєР°Р¶РґРѕРіРѕ С‡Р°РЅРєР° РјС‹ СЃРѕР·РґР°РґРёРј СЃРѕРѕС‚РІРµС‚СЃС‚РІСѓСЋС‰РёР№ РІРµРєС‚РѕСЂРЅС‹Р№ РѕР±СЂР°Р· (СЌРјР±РµРґРґРёРЅРі)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р‘СѓРґРµРј РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ СЌРјР±РµРґРґРёРЅРі РјРѕРґРµР»СЊ РёР· OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р‘СѓРґРµРј РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ РІРµРєС‚РѕСЂРЅРѕРµ С…СЂР°РЅРёР»РёС‰Рµ InMemoryVectorStore (РІ РїР°РјСЏС‚Рё)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    all_splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"openai/text-embedding-3-large\"), # text-embedding-3-large\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РўРµРїРµСЂСЊ СЃРѕР·РґР°РґРёРј retriever РёР· РЅР°С€РµРіРѕ vectorstore РґР»СЏ РїРѕРёСЃРєР° РїРѕ РЅРµРјСѓ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k is the number of chunks to retrieve\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "question = \"Р’С‹ РїСЂРѕРІРѕРґРёС‚Рµ РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё?\"\n",
    "chunks = retriever.invoke(question)\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Skia/PDF m136 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'SMIRNOFF_AI. РџСЂРѕС„РёР»СЊ СЃ РїРѕСЂС‚С„РѕР»РёРѕ', 'source': './documents/smirnoff_ai.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "РЈРЎР›РЈР“Р вЂ”  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- СЂРµС€РµРЅРёР№/Р°РіРµРЅС‚РѕРІ/Р±РѕС‚РѕРІ  РґР»СЏ  Р°РІС‚РѕРјР°С‚РёР·Р°С†РёРё  Р±РёР·РЅРµСЃР°  вЂ”  РђСѓРґРёС‚  РїСЂРѕС†РµСЃСЃРѕРІ  Рё  СЂР°Р·СЂР°Р±РѕС‚РєР°  РґРѕСЂРѕР¶РЅРѕР№  РєР°СЂС‚С‹  РІРЅРµРґСЂРµРЅРёСЏ  AI  вЂ”  РљРѕРЅСЃР°Р»С‚РёРЅРі  РїРѕ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  Рё  РІРЅРµРґСЂРµРЅРёСЋ  AI  вЂ”  РћР±СѓС‡РµРЅРёРµ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  СЂРµС€РµРЅРёР№  РЅР°  Р±Р°Р·Рµ  РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ  РР  \n",
      "РљР›Р®Р§Р•Р’Р«Р•\n",
      " \n",
      "РљРћРњРџР•РўР•РќР¦РР\n",
      " \n",
      "Р\n",
      " \n",
      "РћРџР«Рў\n",
      " \n",
      "РР-Р°СЃСЃРёСЃС‚РµРЅС‚С‹  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- Р°СЃСЃРёСЃС‚РµРЅС‚РѕРІ,  РїРѕРІС‹С€Р°СЋС‰РёС…  СЌС„С„РµРєС‚РёРІРЅРѕСЃС‚СЊ  РІС‹РїРѕР»РЅРµРЅРёСЏ  СЂР°Р±РѕС‡РёС…  Р·Р°РґР°С‡  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ\n"
     ]
    }
   ],
   "source": [
    "print(f\"{chunks[0].metadata}\\n\")\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РњС‹ РІРёРґРёРј, С‡С‚Рѕ РІС‹Р·РѕРІ retriever РІС‹С€Рµ РІРѕР·РІСЂР°С‰Р°РµС‚ РЅРµРєРѕС‚РѕСЂС‹Рµ С‡Р°СЃС‚Рё РґРѕРєСѓРјРµРЅС‚Р°, РєРѕС‚РѕСЂСѓСЋ РЅР°С€ С‡Р°С‚-Р±РѕС‚ РјРѕР¶РµС‚ РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ РІ РєР°С‡РµСЃС‚РІРµ РєРѕРЅС‚РµРєСЃС‚Р° РїСЂРё РѕС‚РІРµС‚Рµ РЅР° РІРѕРїСЂРѕСЃС‹. Р С‚РµРїРµСЂСЊ Сѓ РЅР°СЃ РµСЃС‚СЊ retriever, РєРѕС‚РѕСЂС‹Р№ РјРѕР¶РµС‚ РІРѕР·РІСЂР°С‰Р°С‚СЊ СЃРІСЏР·Р°РЅРЅС‹Рµ РґР°РЅРЅС‹Рµ РёР· РґРѕРєСѓРјРµРЅС‚Р°!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/image_prompt_augmentation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РќР°РїРёС€РµРј С„СѓРЅРєС†РёСЋ РґР»СЏ РѕР±СЉРµРґРёРЅРµРЅРёСЏ С‡Р°РЅРєРѕРІ РІ РѕРґРЅСѓ СЃС‚СЂРѕРєСѓ, С‡С‚РѕР±С‹ РїРѕР·Р¶Рµ РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ РµРµ РІ prompt РґР»СЏ Р·Р°РґР°РЅРёСЏ РєРѕРЅС‚РµРєСЃС‚Р°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat chunks into a single string to insert into the prompt\n",
    "def format_chunks(chunks):\n",
    "    return \"\\n\\n\".join(chunk.page_content for chunk in chunks)\n",
    "\n",
    "chunks_context = format_chunks(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the user question.\n",
    "If you don't find the answer in provided context strictly say 'РЇ РЅРµ РЅР°С€РµР» РѕС‚РІРµС‚Р° РЅР° РІР°С€ РІРѕРїСЂРѕСЃ!'.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate([\n",
    "        (\"system\", SYSTEM_TEMPLATE),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р‘СѓРґРµРј РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ РјРѕРґРµР»СЊ РѕС‚ OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"openai/gpt-oss-20b:free\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РџРѕРїСЂРѕСЃРёРј LLM РѕС‚РІРµС‚РёС‚СЊ РЅР° РІРѕРїСЂРѕСЃ РїРѕ РЅР°Р№РґРµРЅРЅС‹Рј С‡Р°РЅРєР°Рј РІ РєРѕРЅС‚РµРєСЃС‚Рµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Р”Р°, РІ СЂР°РјРєР°С… РЅР°С€РёС… СѓСЃР»СѓРі РјС‹ РїСЂРѕРІРѕРґРёРј РєРѕРЅСЃР°Р»С‚РёРЅРі РїРѕ СЂР°Р·СЂР°Р±РѕС‚РєРµ Рё РІРЅРµРґСЂРµРЅРёСЋ AIвЂ‘СЂРµС€РµРЅРёР№.  \\nРњС‹ РїРѕРјРѕРіР°РµРј Р°СѓРґРёС‚РёСЂРѕРІР°С‚СЊ РїСЂРѕС†РµСЃСЃС‹, СЂР°Р·СЂР°Р±Р°С‚С‹РІР°С‚СЊ РґРѕСЂРѕР¶РЅС‹Рµ РєР°СЂС‚С‹ Рё РѕР±СѓС‡Р°С‚СЊ РєРѕРјР°РЅРґСѓ.  \\nР•СЃР»Рё РЅСѓР¶РЅР° РїРµСЂСЃРѕРЅР°Р»СЊРЅР°СЏ РєРѕРЅСЃСѓР»СЊС‚Р°С†РёСЏ, СѓС‚РѕС‡РЅРёС‚Рµ РґРµС‚Р°Р»Рё, Рё РјС‹ РїРѕРґР±РµСЂС‘Рј РїРѕРґС…РѕРґСЏС‰РёР№ РїР°РєРµС‚.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 516, 'total_tokens': 644, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b:free', 'system_fingerprint': None, 'id': 'gen-1762461315-zDJ7EtlulmhwifdPPr7d', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f3556f1a-4d12-473a-bc39-b6c3885b9ac9-0', usage_metadata={'input_tokens': 516, 'output_tokens': 128, 'total_tokens': 644, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm.invoke(question_answering_prompt.invoke(\n",
    "    {\n",
    "        \"context\": chunks_context,\n",
    "        \"question\": question,\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’С‹РіР»СЏРґРёС‚ С…РѕСЂРѕС€Рѕ! Р”Р»СЏ СЃСЂР°РІРЅРµРЅРёСЏ РїРѕРїСЂРѕР±СѓРµРј Р±РµР· РєРѕРЅС‚РµРєСЃС‚РЅС‹С… РґРѕРєСѓРјРµРЅС‚РѕРІ Рё СЃСЂР°РІРЅРёРј СЂРµР·СѓР»СЊС‚Р°С‚:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='РЇ РЅРµ РЅР°С€РµР» РѕС‚РІРµС‚Р° РЅР° РІР°С€ РІРѕРїСЂРѕСЃ!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 135, 'total_tokens': 247, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b:free', 'system_fingerprint': None, 'id': 'gen-1762461328-3MpNeA7VTIksEbrHohWv', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8d1b3862-9500-45e8-bd4b-c87a4dfdaff6-0', usage_metadata={'input_tokens': 135, 'output_tokens': 112, 'total_tokens': 247, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(question_answering_prompt.invoke(\n",
    "    {\n",
    "        \"context\": \"\",\n",
    "        \"question\": question,\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р‘СЂР°РІРѕ! РњС‹ СЃ РІР°РјРё СЃРѕР·РґР°Р»Рё РїРµСЂРІСѓСЋ RAG СЃРёСЃС‚РµРјСѓ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Retrieval chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Р”Р°РІР°Р№С‚Рµ С‚РµРїРµСЂСЊ СЃРѕР·РґР°РґРёРј С†РµРїРѕС‡РєСѓ chain, РєРѕС‚РѕСЂР°СЏ Р±СѓРґРµС‚ РїСЂРёРЅРёРјР°С‚СЊ РІРѕРїСЂРѕСЃ РѕС‚ РїРѕР»СЊР·РѕРІР°С‚РµР»СЏ Рё РІРѕР·РІСЂР°С‰Р°С‚СЊ РѕС‚РІРµС‚ РЅР° РѕСЃРЅРѕРІРµ РЅР°Р№РґРµРЅРЅС‹С… С‡Р°РЅРєРѕРІ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_chunks, \"question\": RunnablePassthrough()}\n",
    "    | question_answering_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РџРѕСЃРјРѕС‚СЂРёС‚Рµ, РєР°Рє СѓРґРѕР±РЅРѕ С‚РµРїРµСЂСЊ РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊ - РѕРґРЅР° СЃС‚СЂРѕС‡РєР° РєРѕРґР° Рё РјС‹ РїРѕР»СѓС‡Р°РµРј РѕС‚РІРµС‚ РЅР° РЅР°С€ РІРѕРїСЂРѕСЃ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Р”Р°, РјС‹ РїСЂРѕРІРѕРґРёРј РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё РїРѕ СЂР°Р·СЂР°Р±РѕС‚РєРµ Рё РІРЅРµРґСЂРµРЅРёСЋ РРвЂ‘СЂРµС€РµРЅРёР№.  \\nРќР°С€Р° РєРѕРјР°РЅРґР° РїСЂРѕРІРѕРґРёС‚ Р°СѓРґРёС‚ РїСЂРѕС†РµСЃСЃРѕРІ, СЂР°Р·СЂР°Р±Р°С‚С‹РІР°РµС‚ РґРѕСЂРѕР¶РЅСѓСЋ РєР°СЂС‚Сѓ РІРЅРµРґСЂРµРЅРёСЏ Рё РїСЂРµРґРѕСЃС‚Р°РІР»СЏРµС‚ СЂРµРєРѕРјРµРЅРґР°С†РёРё РїРѕ РѕРїС‚РёРјРёР·Р°С†РёРё.  \\nРњС‹ РїРѕРјРѕРіР°РµРј СѓСЃРєРѕСЂРёС‚СЊ РїРµСЂРµС…РѕРґ РЅР° РР Рё РїРѕРІС‹СЃРёС‚СЊ СЌС„С„РµРєС‚РёРІРЅРѕСЃС‚СЊ РІР°С€РµРіРѕ Р±РёР·РЅРµСЃР°.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’С‹РіР»СЏРґРёС‚ С…РѕСЂРѕС€Рѕ!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЎРѕР·РґР°РґРёРј С€Р°Р±Р»РѕРЅ РїСЂРѕРјРїС‚Р° РґР»СЏ СѓС‡РµС‚Р° РІСЃРµР№ РёСЃС‚РѕСЂРёРё РґРёР°Р»РѕРіР°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"\\nYou are an assistant for question-answering tasks. Answer the user's questions based on the conversation history and below context retrieved for the last question. Answer 'РЇ РЅРµ РЅР°С€РµР» РѕС‚РІРµС‚Р° РЅР° РІР°С€ РІРѕРїСЂРѕСЃ!' if you don't find any information in the context. Use three sentences maximum and keep the answer concise.\\n\\nContext retrieved for the last question:\\n\\nР§Р°РЅРєРё РєРѕРЅС‚РµРєСЃС‚Р°\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Р’С‹ РїСЂРѕРІРѕРґРёС‚Рµ РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "CONVERSATION_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Answer the user's questions based on the conversation history and below context retrieved for the last question. Answer 'РЇ РЅРµ РЅР°С€РµР» РѕС‚РІРµС‚Р° РЅР° РІР°С€ РІРѕРїСЂРѕСЃ!' if you don't find any information in the context. Use three sentences maximum and keep the answer concise.\\n\\nContext retrieved for the last question:\\n\\n{context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "conversational_answering_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", CONVERSATION_SYSTEM_TEMPLATE),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "conversational_answering_prompt.invoke(\n",
    "    {\n",
    "        \"context\": \"Р§Р°РЅРєРё РєРѕРЅС‚РµРєСЃС‚Р°\",\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=question)\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р РµР°Р»РёР·СѓРµРј С†РµРїРѕС‡РєСѓ РѕС‚РІРµС‚Р° РЅР° РїРѕСЃР»РµРґРЅРёР№ Р·Р°РґР°РЅРЅС‹Р№ РІРѕРїСЂРѕСЃ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def get_last_message_for_retriever_input(params: Dict):\n",
    "    return params[\"messages\"][-1].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'РЈРЎР›РЈР“Р вЂ”  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- СЂРµС€РµРЅРёР№/Р°РіРµРЅС‚РѕРІ/Р±РѕС‚РѕРІ  РґР»СЏ  Р°РІС‚РѕРјР°С‚РёР·Р°С†РёРё  Р±РёР·РЅРµСЃР°  вЂ”  РђСѓРґРёС‚  РїСЂРѕС†РµСЃСЃРѕРІ  Рё  СЂР°Р·СЂР°Р±РѕС‚РєР°  РґРѕСЂРѕР¶РЅРѕР№  РєР°СЂС‚С‹  РІРЅРµРґСЂРµРЅРёСЏ  AI  вЂ”  РљРѕРЅСЃР°Р»С‚РёРЅРі  РїРѕ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  Рё  РІРЅРµРґСЂРµРЅРёСЋ  AI  вЂ”  РћР±СѓС‡РµРЅРёРµ  СЂР°Р·СЂР°Р±РѕС‚РєРµ  СЂРµС€РµРЅРёР№  РЅР°  Р±Р°Р·Рµ  РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ  РР  \\nРљР›Р®Р§Р•Р’Р«Р•\\n \\nРљРћРњРџР•РўР•РќР¦РР\\n \\nР\\n \\nРћРџР«Рў\\n \\nРР-Р°СЃСЃРёСЃС‚РµРЅС‚С‹  Р Р°Р·СЂР°Р±РѕС‚РєР°  AI- Р°СЃСЃРёСЃС‚РµРЅС‚РѕРІ,  РїРѕРІС‹С€Р°СЋС‰РёС…  СЌС„С„РµРєС‚РёРІРЅРѕСЃС‚СЊ  РІС‹РїРѕР»РЅРµРЅРёСЏ  СЂР°Р±РѕС‡РёС…  Р·Р°РґР°С‡  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ\\n\\nРР-РњР•РќР•Р”Р–Р•Р \\n \\nРџРћ\\n \\nРџР РћР”РђР–РђРњ\\n \\nРРќРўР•Р РќР•Рў-РњРђР“РђР—РРќРђ\\n \\nР—РђРџР§РђРЎРўР•Р™\\n \\nР‘Р«РўРћР’РћР™\\n \\nРўР•РҐРќРРљР\\n  Р—Р°РєР°Р·С‡РёРє :  Zip-KRD  вЂ”  РёРЅС‚РµСЂРЅРµС‚-РјР°РіР°Р·РёРЅ  РїРѕ  РїСЂРѕРґР°Р¶Рµ  Р·Р°РїС‡Р°СЃС‚РµР№  Рё  Р°РєСЃРµСЃСЃСѓР°СЂРѕРІ  РґР»СЏ  Р±С‹С‚РѕРІРѕР№  С‚РµС…РЅРёРєРё   РџСЂРѕР±Р»РµРјР°С‚РёРєР°,  Р·Р°РґР°С‡Р°:  -  Р‘РѕР»СЊС€РѕР№  РїРѕС‚РѕРє  РєР»РёРµРЅС‚РѕРІ  Рё  РІРѕРїСЂРѕСЃРѕРІ,  РєРѕС‚РѕСЂС‹Рµ  РјРµРЅРµРґР¶РµСЂС‹  РЅРµ  СѓСЃРїРµРІР°СЋС‚  \\nРѕС‚СЂР°Р±Р°С‚С‹РІР°С‚СЊ\\n \\nРІ\\n \\nСЂРµР¶РёРјРµ\\n \\n24С…7\\n\\n-  РњРіРЅРѕРІРµРЅРЅС‹Рµ  РѕС‚РІРµС‚С‹  РЅР°  РІРѕРїСЂРѕСЃС‹  РєР»РёРµРЅС‚РѕРІ  24С…7,  РѕС‚Р·С‹РІС‡РёРІРѕСЃС‚СЊ  СЃРёСЃС‚РµРјС‹  -  РџРѕРІС‹С€РµРЅРёРµ  РєРѕРЅРІРµСЂСЃРёРё  РѕР±СЂР°С‰РµРЅРёР№  РІ  Р·Р°РєР°Р·С‹,  РїРѕРІС‹С€РµРЅРёРµ  Р»РѕСЏР»СЊРЅРѕСЃС‚Рё  РєР»РёРµРЅС‚РѕРІ  -  Р­РєРѕРЅРѕРјРёСЏ  Р¤РћРў  СЃРѕС‚СЂСѓРґРЅРёРєРѕРІ,  РјРµРЅРµРґР¶РµСЂС‹  РЅРµ  С‚СЂР°С‚СЏС‚  РІСЂРµРјСЏ  РЅР°  РїСЂРѕСЃС‚С‹Рµ  РґРёР°Р»РѕРіРё  Рё  \\nРѕС‚СЂР°Р±Р°С‚С‹РІР°СЋС‚\\n \\nС‚РѕР»СЊРєРѕ\\n \\nвЂњРѕСЃРѕР±С‹РµвЂќ\\n \\nСЃР»СѓС‡Р°Рё'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message_retriever_chain = get_last_message_for_retriever_input | retriever | format_chunks \n",
    "last_message_retriever_chain.invoke({\"messages\": [\n",
    "            HumanMessage(content=question)\n",
    "        ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=get_last_message_for_retriever_input | retriever | format_chunks\n",
    "    )\n",
    "    | conversational_answering_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РџСЂРѕС‚РµСЃС‚РёСЂСѓРµРј РЅР°С€Сѓ РЅРѕРІСѓСЋ РґРёР°Р»РѕРіРѕРІСѓСЋ С†РµРїРѕС‡РєСѓ СЃ РѕРґРЅРёРј СЃРѕРѕР±С‰РµРЅРёРµРј"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Р’С‹ РїСЂРѕРІРѕРґРёС‚Рµ РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Р РµР·СѓР»СЊС‚Р°С‚ РґРёР°Р»РѕРіР°: Р”Р°, РјС‹ РїСЂРѕРІРѕРґРёРј РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё РїРѕ СЂР°Р·СЂР°Р±РѕС‚РєРµ Рё РІРЅРµРґСЂРµРЅРёСЋ AIвЂ‘СЂРµС€РµРЅРёР№.  \n",
      "РњС‹ РїРѕРјРѕРіР°РµРј Р°СѓРґРёС‚РёСЂРѕРІР°С‚СЊ РїСЂРѕС†РµСЃСЃС‹, СЂР°Р·СЂР°Р±Р°С‚С‹РІР°С‚СЊ РґРѕСЂРѕР¶РЅСѓСЋ РєР°СЂС‚Сѓ Рё РєРѕРЅСЃСѓР»СЊС‚РёСЂСѓРµРј РїРѕ РІСЃРµРј СЌС‚Р°РїР°Рј РїСЂРѕРµРєС‚Р°.  \n",
      "Р•СЃР»Рё РЅСѓР¶РЅР° Р±РѕР»РµРµ РїРѕРґСЂРѕР±РЅР°СЏ РёРЅС„РѕСЂРјР°С†РёСЏ, РїСЂРѕСЃС‚Рѕ РґР°Р№С‚Рµ Р·РЅР°С‚СЊ.\n"
     ]
    }
   ],
   "source": [
    "# РўРµСЃС‚РёСЂСѓРµРј РґРёР°Р»РѕРі СЃ РѕРґРЅРёРј СЃРѕРѕР±С‰РµРЅРёРµРј\n",
    "answer = rag_conversation_chain.invoke({\"messages\": [\n",
    "    HumanMessage(content=question)\n",
    "]})\n",
    "print(\"Р РµР·СѓР»СЊС‚Р°С‚ РґРёР°Р»РѕРіР°:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’СЃРµ РїСЂРµРєСЂР°СЃРЅРѕ. РњС‹ РїРѕР»СѓС‡РёР»Рё Р°РґРµРєРІР°С‚РЅС‹Р№ РѕС‚РІРµС‚ РЅР° РЅР°С€ РІРѕРїСЂРѕСЃ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РўРµРїРµСЂСЊ Р·Р°РґР°РґРёРј СѓС‚РѕС‡РЅСЏСЋС‰РёР№ РІРѕРїСЂРѕСЃ \"Рђ РµС‰С‘ РєР°РєРёРµ?\" (РёРјРµСЏ РІРІРёРґСѓ, Р° РєР°РєРёРµ РµС‰Рµ СѓСЃР»СѓРіРё РёР»Рё РєРѕРЅСЃСѓР»СЊС‚Р°С†РёРё РїСЂРµРґРѕСЃС‚Р°РІР»СЏСЋС‚СЃСЏ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"Рђ РµС‰С‘ РєР°РєРёРµ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Р РµР·СѓР»СЊС‚Р°С‚ РґРёР°Р»РѕРіР° СЃ РЅРµСЃРєРѕР»СЊРєРёРјРё СЃРѕРѕР±С‰РµРЅРёСЏРјРё: РњС‹ С‚Р°РєР¶Рµ РїСЂРµРґР»Р°РіР°РµРј СѓСЃР»СѓРіРё РїРѕ РёРЅС‚РµРіСЂР°С†РёРё Рё Р°РІС‚РѕРјР°С‚РёР·Р°С†РёРё Р±РёР·РЅРµСЃвЂ‘РїСЂРѕС†РµСЃСЃРѕРІ, РЅР°СЃС‚СЂРѕР№РєРµ DevOps Рё MLOps, Р° С‚Р°РєР¶Рµ РєСЂРѕСЃСЃвЂ‘РїР»Р°С‚С„РѕСЂРјРµРЅРЅРѕРµ С‚РµСЃС‚РёСЂРѕРІР°РЅРёРµ Рё Р°СѓРґРёС‚ РґР°РЅРЅС‹С….  \n",
      "РљСЂРѕРјРµ С‚РѕРіРѕ, Р·Р°РЅРёРјР°РµРјСЃСЏ РѕР±СѓС‡РµРЅРёРµРј РєРѕРјР°РЅРґС‹ Рё СЂР°Р·СЂР°Р±РѕС‚РєРѕР№ РїРѕР»СЊР·РѕРІР°С‚РµР»СЊСЃРєРёС… AIвЂ‘РјРѕРґРµР»РµР№ СЃ РёСЃРїРѕР»СЊР·РѕРІР°РЅРёРµРј PyTorch, LangChain Рё Haystack.  \n",
      "Р•СЃР»Рё РЅСѓР¶РЅРѕ СѓС‚РѕС‡РЅРёС‚СЊ РґРµС‚Р°Р»Рё, РґР°Р№С‚Рµ Р·РЅР°С‚СЊ.\n"
     ]
    }
   ],
   "source": [
    "# РўРµСЃС‚РёСЂСѓРµРј РїРѕР»РЅС‹Р№ РґРёР°Р»РѕРі СЃ РЅРµСЃРєРѕР»СЊРєРёРјРё СЃРѕРѕР±С‰РµРЅРёСЏРјРё\n",
    "dialog_result = rag_conversation_chain.invoke({\"messages\": [\n",
    "    HumanMessage(content=question), \n",
    "    AIMessage(content=answer),\n",
    "    HumanMessage(content=question2), # \"Рђ РµС‰С‘ РєР°РєРёРµ?\"\n",
    "]})\n",
    "print(\"Р РµР·СѓР»СЊС‚Р°С‚ РґРёР°Р»РѕРіР° СЃ РЅРµСЃРєРѕР»СЊРєРёРјРё СЃРѕРѕР±С‰РµРЅРёСЏРјРё:\", dialog_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’РёРґРёРј РїСЂРѕР±Р»РµРјСѓ! РќР°С€Р° С†РµРїРѕС‡РєР° РЅРµ СЃРјРѕРіР»Р° РЅР°Р№С‚Рё РѕС‚РІРµС‚ РЅР° РІРѕРїСЂРѕСЃ.\n",
    "Р РґРµР№СЃС‚РІРёС‚РµР»СЊРЅРѕ СЃР°Рј РІРѕРїСЂРѕСЃ \"Рђ РєР°РєРёРµ РµС‰Рµ?\" РЅРµ РЅРµСЃРµС‚ РІ СЃРµР±Рµ СЃРјС‹СЃР»Р° Р±РµР· РїРѕРЅРёРјР°РЅРёСЏ РёСЃС‚РѕСЂРёРё РґРёР°Р»РѕРіР°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РњС‹ РїРѕРЅРёРјР°РµРј, С‡С‚Рѕ С‡Р°С‚-Р±РѕС‚С‹ РІР·Р°РёРјРѕРґРµР№СЃС‚РІСѓСЋС‚ СЃ РїРѕР»СЊР·РѕРІР°С‚РµР»СЏРјРё РІ СЂРµР¶РёРјРµ Р±РµСЃРµРґС‹ Рё РїРѕСЌС‚РѕРјСѓ РґРѕР»Р¶РЅС‹ СЃРїСЂР°РІР»СЏС‚СЊСЃСЏ СЃ СѓС‚РѕС‡РЅСЏСЋС‰РёРјРё РІРѕРїСЂРѕСЃР°РјРё."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р”Р°РІР°Р№С‚Рµ РїРѕСЃРјРѕС‚СЂРёРј РЅР° С‡Р°РЅРєРё, РєРѕС‚РѕСЂС‹Рµ РјС‹ РїРѕР»СѓС‡РёР»Рё РїСЂРё РѕС‚РІРµС‚Рµ РЅР° РІРѕРїСЂРѕСЃ `Рђ РµС‰С‘ С‡С‚Рѕ?`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Python,  PyTorch,  Haystack,  LangChain,  LangGraph  Рё  РґСЂ.  Data:  MongoDB,  PostgreSQL,  Dremio,  Kafka  Рё  РґСЂ.  DevOps: Docker,  Ansible,  Kubernetes,  Airп¬‚ow  Рё  РґСЂ.  Cloud: Yandex  Cloud,  Terraform  Рё  РґСЂ.  \n",
      "РџР РћР¦Р•РЎРЎР«/РџР РђРљРўРРљР\n",
      " \n",
      "  Agile,  XP,  Microservices,  CI/CD,   IaC,  GitOps,  DocOps,  MLOps  \n",
      "РќРђР“Р РђР”Р«\n",
      " \n",
      "  РР-С…Р°РєР°С‚РѕРЅС‹  вЂњР¦РёС„СЂРѕРІРѕР№  РїСЂРѕСЂС‹РІвЂќ:  -  РњРµР¶РґСѓРЅР°СЂРѕРґРЅС‹Рµ  2024,  2023  -  Р РµРіРёРѕРЅР°Р»СЊРЅС‹Рµ  2024,  2023  РџР РћР¤- IT. РРЅРЅРѕРІР°С†РёСЏ  2023,2021  РџСЂРµРјРёСЏ  Р СѓРЅРµС‚Р°  2019  \n",
      "РЎР•Р РўРР¤РРљРђРўР«\n"
     ]
    }
   ],
   "source": [
    "result_chunks = retriever.invoke(question2)\n",
    "\n",
    "print(result_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’РёРґРёРј, С‡С‚Рѕ С‡Р°РЅРє РЅРµ СЃРѕРґРµСЂР¶РёС‚ РёРЅС„РѕСЂРјР°С†РёРё Рѕ РґСЂСѓРіРёС… СѓСЃР»СѓРіР°С…. Р—РЅР°С‡РёС‚ РјС‹ Р±С‹Р»Рё РїСЂР°РІС‹ РІ СЃРІРѕРµРј РїСЂРµРґРїРѕР»РѕР¶РµРЅРёРё Рѕ С‚РѕРј, С‡С‚Рѕ retriever РЅРµ РЅР°С€РµР» РЅСѓР¶РЅРѕР№ РёРЅС„РѕСЂРјР°С†РёРё РЅР° Р·Р°РїСЂРѕСЃ \"Рђ РµС‰Рµ РєР°РєРёРµ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Р§С‚РѕР±С‹ СЂРµС€РёС‚СЊ СЌС‚Сѓ РїСЂРѕР±Р»РµРјСѓ, РјС‹ РјРѕР¶РµРј СЃРѕР·РґР°С‚СЊ РґР»СЏ retriever РїСЂР°РІРёР»СЊРЅС‹Р№ РїРѕРёСЃРєРѕРІС‹Р№ Р·Р°РїСЂРѕСЃ РЅР° РѕСЃРЅРѕРІРµ РІСЃРµР№ РёСЃС‚РѕСЂРёРё РїРµСЂРµРїРёСЃРєРё.\n",
    "\n",
    "РџСЂРёРјРµРЅРёРј С‚РµС…РЅРёРєСѓ Query Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "retrieval_query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Transform last user message to a search query in Russian language according to the whole conversation history above to further retrieve the information relevant to the conversation. Try to thorougly analyze all message to generate the most relevant query. The longer result better than short. Let it be better more abstract than specific. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_query_transform = ChatOpenAI(model=\"gpt-4o\", temperature=0.4)\n",
    "\n",
    "retrieval_query_transformation_chain = retrieval_query_transform_prompt | llm_query_transform | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РњС‹ СЃРѕР·РґР°Р»Рё С†РµРїРѕС‡РєСѓ РґР»СЏ РїРµСЂРµРїРёСЃС‹РІР°РЅРёСЏ (С‚СЂР°РЅСЃС„РѕСЂРјС†РёРё) РїРѕР»СЊР·РѕРІР°С‚РµР»СЊСЃРєРѕРіРѕ СЃРѕРѕР±С‰РµРЅРёСЏ РІ РїРѕРёСЃРєРѕРІС‹Р№ Р·Р°РїСЂРѕСЃ РґР»СЏ retriever. РџСЂРѕРІРµСЂРёРј РµРµ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'РґРѕРїРѕР»РЅРёС‚РµР»СЊРЅС‹Рµ РІРёРґС‹ РєРѕРЅСЃСѓР»СЊС‚Р°С†РёР№ Рё СѓСЃР»СѓРі, РїСЂРµРґРѕСЃС‚Р°РІР»СЏРµРјС‹С… РІ РѕР±Р»Р°СЃС‚Рё РёСЃРєСѓСЃСЃС‚РІРµРЅРЅРѕРіРѕ РёРЅС‚РµР»Р»РµРєС‚Р° Рё С‚РµС…РЅРѕР»РѕРіРёР№'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_query_transformation_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=question), #РљР°РєРёРµ СѓСЃР»СѓРіРё РїСЂРµРґРѕСЃС‚Р°РІР»СЏСЋС‚СЃСЏ?\n",
    "            AIMessage(\n",
    "                content=answer #Р”Р°, РјС‹ РїСЂРѕРІРѕРґРёРј РєРѕРЅСЃР°Р»С‚РёРЅРі РїРѕ СЂР°Р·СЂР°Р±РѕС‚РєРµ Рё РІРЅРµРґСЂРµРЅРёСЋ AI.\n",
    "            ),\n",
    "            HumanMessage(content=question2), #Рђ РµС‰С‘ РєР°РєРёРµ?\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЎСѓРїРµСЂ! РњС‹ РІРёРґРёРј РѕСЃРјС‹СЃР»РµРЅРЅС‹Р№ Р·Р°РїСЂРѕСЃ РІРјРµСЃС‚Рѕ Р°Р±СЃС‚СЂР°РєС‚РЅРѕРіРѕ \"Рђ РєР°РєРёРµ РµС‰Рµ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р”Р°РІР°Р№С‚Рµ С‚РµРїРµСЂСЊ СЃРѕР·РґР°РґРёРј С†РµРїРѕС‡РєСѓ, РєРѕС‚РѕСЂР°СЏ Р±СѓРґРµС‚ РёСЃРїРѕР»СЊР·РѕРІР°С‚СЊСЃСЏ РґР»СЏ РѕС‚РІРµС‚Р° РЅР° РІРѕРїСЂРѕСЃС‹, СѓС‡РёС‚С‹РІР°СЏ РёСЃС‚РѕСЂРёСЋ РїРµСЂРµРїРёСЃРєРё. Р­С‚Р° С†РµРїРѕС‡РєР° РґРѕР»Р¶РЅР° СѓРјРµС‚СЊ РѕС‚РІРµС‡Р°С‚СЊ РЅР° СѓС‚РѕС‡РЅСЏСЋС‰РёРµ РІРѕРїСЂРѕСЃС‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query_transform_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context= retrieval_query_transformation_chain | retriever | format_chunks\n",
    "    )\n",
    "    | conversational_answering_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р¦РµРїРѕС‡РєР° СЃРѕР·РґР°РЅР°. РўРµРїРµСЂСЊ РїСЂРѕРІРµСЂРёРј РµРµ РЅР° РЅР°С€РёС… РЅРµСЃРєРѕР»СЊРєРёС… СЃРѕРѕР±С‰РµРЅРёСЏС…:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'РљСЂРѕРјРµ РєРѕРЅСЃР°Р»С‚РёРЅРіР°, РјС‹ РїСЂРµРґР»Р°РіР°РµРј СЂР°Р·СЂР°Р±РѕС‚РєСѓ AI-СЂРµС€РµРЅРёР№, Р°СѓРґРёС‚ РїСЂРѕС†РµСЃСЃРѕРІ Рё РѕР±СѓС‡РµРЅРёРµ СЂР°Р·СЂР°Р±РѕС‚РєРµ СЂРµС€РµРЅРёР№ РЅР° Р±Р°Р·Рµ РіРµРЅРµСЂР°С‚РёРІРЅРѕРіРѕ РР. РўР°РєР¶Рµ РјРѕР¶РµРј РїСЂРµРґРѕСЃС‚Р°РІРёС‚СЊ СѓСЃР»СѓРіРё РїРѕ РІРЅРµРґСЂРµРЅРёСЋ РР РІ СЃСѓС‰РµСЃС‚РІСѓСЋС‰РёРµ СЃРёСЃС‚РµРјС‹.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query_transform_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=question), #РљР°РєРёРµ СѓСЃР»СѓРіРё РїСЂРµРґРѕСЃС‚Р°РІР»СЏСЋС‚СЃСЏ?\n",
    "            AIMessage(\n",
    "                content=answer #Р”Р°, РјС‹ РїСЂРѕРІРѕРґРёРј РєРѕРЅСЃР°Р»С‚РёРЅРі РїРѕ СЂР°Р·СЂР°Р±РѕС‚РєРµ Рё РІРЅРµРґСЂРµРЅРёСЋ AI.\n",
    "            ),\n",
    "            HumanMessage(content=question2), #Рђ РµС‰С‘ РєР°РєРёРµ?\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Р’СЃРµ! РўРµРїРµСЂСЊ Сѓ РЅР°СЃ РµСЃС‚СЊ С†РµРїРѕС‡РєР° РіРѕС‚РѕРІР°СЏ РґР»СЏ РІРЅРµРґСЂРµРЅРёСЏ РІ РЅР°С€ Р±РѕС‚!\n",
    "РЈСЂР° :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РџСЂР°РєС‚РёРєР° С‚СЂР°РЅСЃС„РѕСЂРјР°С†РёРё Р·Р°РїСЂРѕСЃР°, СЂР°СЃСЃРјРѕС‚СЂРµРЅРЅР°СЏ РЅР°РјРё, - СЌС‚Рѕ РІСЃРµРіРѕ Р»РёС€СЊ РѕРґРЅР° РёР· РјРЅРѕР¶РµСЃС‚РІР° РїСЂР°РєС‚РёРє Рё РїРѕРґС…РѕРґРѕРІ РїРѕСЃС‚СЂРѕРµРЅРёСЏ RAG-СЃРёСЃС‚РµРјС‹ РІ СЂРµР°Р»СЊРЅРѕР№ Р¶РёР·РЅРё РґР»СЏ СЂР°Р±РѕС‚С‹ СЃ СЂРµР°Р»СЊРЅС‹РјРё РґРѕРєСѓРјРµРЅС‚Р°РјРё Рё Р±Р°Р·Р°РјРё Р·РЅР°РЅРёР№:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![RAG](slides/image_advanced.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_notebook_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
