[project]
name = "telegram-llm-bot"
version = "0.1.0"
description = "Simple Telegram bot with LLM integration"
requires-python = ">=3.11"
dependencies = [
    "aiogram>=3.15.0",
    "openai>=1.54.0",
    "python-dotenv>=1.0.0",
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",
    "langchain-community>=0.3.0",
    "langchain-core>=0.3.0",
    "langchain-text-splitters>=0.3.0",
    "langchain-huggingface>=0.1.0",
    "langchain-classic>=0.3.0",
    "pypdf>=5.0.0",
    "langsmith>=0.1.0",
    "jq>=1.0.0",
    "ragas>=0.2.0",
    "datasets>=3.0.0",
    "sentence-transformers>=3.0.0",
    "rank-bm25>=0.2.0",
    "protobuf>=6.33.1",
    "sentencepiece>=0.2.1",
    "accelerate>=1.11.0",
    "bitsandbytes>=0.48.2",
    # PyTorch with CUDA support (for GPU acceleration)
    # Note: Install from PyTorch index: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    # This is commented out because uv doesn't support custom indexes in pyproject.toml
    # Run manually: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
]

