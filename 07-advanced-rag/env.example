# ============================================================
# TELEGRAM BOT CONFIGURATION
# ============================================================

# Получить токен у @BotFather в Telegram
TELEGRAM_TOKEN=

# ============================================================
# LLM PROVIDER CONFIGURATION
# Выберите один из провайдеров и раскомментируйте нужный блок
# ============================================================

# --- OpenAI (официальный API) ---
# OPENAI_API_KEY=sk-proj-...
# MODEL=gpt-4o
# MODEL_QUERY_TRANSFORM=gpt-4o
# EMBEDDING_MODEL=text-embedding-3-large
# RAGAS_LLM_MODEL=gpt-4o
# RAGAS_EMBEDDING_MODEL=text-embedding-3-large

# --- OpenRouter (рекомендуется) ---
# https://openrouter.ai/ - доступ к различным моделям
# OPENAI_API_KEY=sk-or-v1-...
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# MODEL=openai/gpt-oss-20b:free
# MODEL_QUERY_TRANSFORM=openai/gpt-oss-20b:free
# EMBEDDING_MODEL=openai/text-embedding-3-large
# RAGAS_LLM_MODEL=openai/gpt-oss-20b:free
# RAGAS_EMBEDDING_MODEL=openai/text-embedding-3-large

# --- Fireworks (быстро, но embedding слабее) ---
# https://fireworks.ai/
# OPENAI_API_KEY=fw_...
# OPENAI_BASE_URL=https://api.fireworks.ai/inference/v1
# MODEL=accounts/fireworks/models/gpt-oss-120b
# MODEL_QUERY_TRANSFORM=accounts/fireworks/models/gpt-oss-120b
# EMBEDDING_MODEL=accounts/fireworks/models/qwen3-embedding-8b
# RAGAS_LLM_MODEL=accounts/fireworks/models/gpt-oss-120b
# RAGAS_EMBEDDING_MODEL=accounts/fireworks/models/qwen3-embedding-8b

# ============================================================
# PATHS & FILES
# ============================================================

DATA_DIR=data
PROMPTS_DIR=prompts
CONVERSATION_SYSTEM_PROMPT_FILE=conversation_system.txt
QUERY_TRANSFORM_PROMPT_FILE=query_transform.txt

# ============================================================
# ADVANCED HYBRID RAG CONFIGURATION
# ============================================================

# --- Retrieval Mode ---
# semantic          - векторный поиск по смыслу (по умолчанию)
# hybrid            - Semantic + BM25 (точные термины)
# hybrid_reranker   - Hybrid + Cross-encoder (максимальная точность)
RETRIEVAL_MODE=semantic

# --- Retriever Parameters ---
SEMANTIC_RETRIEVER_K=10
BM25_RETRIEVER_K=10

# --- Ensemble Weights (для hybrid режима) ---
ENSEMBLE_SEMANTIC_WEIGHT=0.5
ENSEMBLE_BM25_WEIGHT=0.5

# --- Cross-Encoder Reranking (для hybrid_reranker режима) ---
CROSS_ENCODER_MODEL=cross-encoder/mmarco-mMiniLMv2-L12-H384-v1
RERANKER_TOP_K=3

# ============================================================
# EMBEDDINGS CONFIGURATION
# ============================================================

# --- Provider ---
# openai      - облачные embeddings (быстрый старт)
# huggingface - локальные модели (приватность, offline)
EMBEDDING_PROVIDER=huggingface

# --- HuggingFace Settings (если EMBEDDING_PROVIDER=huggingface) ---
HUGGINGFACE_EMBEDDING_MODEL=intfloat/multilingual-e5-base
HUGGINGFACE_DEVICE=cpu  # cpu, cuda, mps (Mac M1/M2)

# Отключает параллелизм в tokenizers для избежания предупреждений
# в многопроцессном окружении (aiogram + asyncio)
TOKENIZERS_PARALLELISM=false

# ============================================================
# FEATURES
# ============================================================

# Отображать источники документов в ответах
SHOW_SOURCES=false

# ============================================================
# RAGAS EVALUATION
# ============================================================

# --- LLM Provider для RAGAS ---
# openai      - внешний API (OpenAI/Fireworks) - быстро, но платно
# huggingface - локальная модель - бесплатно, но требует ресурсов
# RAGAS_LLM_PROVIDER=openai
# RAGAS_LLM_PROVIDER=huggingface

# --- LLM Model (если RAGAS_LLM_PROVIDER=openai) ---
# Для OpenAI: gpt-4o, gpt-4-turbo, etc.
# Для Fireworks: accounts/fireworks/models/gpt-oss-120b
# RAGAS_LLM_MODEL=gpt-4o

# --- HuggingFace LLM Settings (если RAGAS_LLM_PROVIDER=huggingface) ---
# Рекомендуемые модели для русского языка:
# - IlyaGusev/saiga2_7b_lora (лучшее качество для русского, ~14GB RAM)
# - IlyaGusev/saiga2_13b_lora (еще лучше, но ~26GB RAM, нужен GPU)
# - Qwen/Qwen2.5-7B-Instruct (хорошая мультиязычная, ~14GB RAM)
# - deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B (быстрая, но слабее, ~3GB RAM)
# RAGAS_HUGGINGFACE_LLM_MODEL=IlyaGusev/saiga2_7b_lora
# RAGAS_HUGGINGFACE_LLM_DEVICE=auto  # auto/cpu/cuda (auto = автоматический выбор)
# RAGAS_HUGGINGFACE_LLM_QUANTIZATION=none  # none/4bit/8bit (для экономии памяти)

# --- Embeddings Provider для RAGAS (по умолчанию = EMBEDDING_PROVIDER) ---
# openai      - OpenAI embeddings (рекомендуется для стабильных метрик)
# huggingface - локальные HuggingFace embeddings
# RAGAS_EMBEDDING_PROVIDER=huggingface

# --- HuggingFace настройки для RAGAS (если RAGAS_EMBEDDING_PROVIDER=huggingface) ---
# По умолчанию использует те же модели что и основные embeddings
# RAGAS_HUGGINGFACE_EMBEDDING_MODEL=intfloat/multilingual-e5-base
# RAGAS_HUGGINGFACE_DEVICE=cpu

# --- Rate Limit Protection (для внешних API, например Fireworks) ---
# Количество повторных попыток при ошибках rate limit (429) (по умолчанию: 20)
# RAGAS_MAX_RETRIES=20
# Максимальное время ожидания между попытками в секундах (30 минут по умолчанию)
# RAGAS_MAX_WAIT=1800
# Таймаут для одного запроса в секундах (2 минуты по умолчанию)
# RAGAS_REQUEST_TIMEOUT=120.0
# Задержка между запросами в секундах для предотвращения rate limit (по умолчанию: 2.0)
# Увеличьте до 3-5 секунд, если все еще получаете 429 ошибки
# RAGAS_REQUEST_DELAY=2.0

# ============================================================
# LANGSMITH MONITORING (опционально)
# ============================================================

# Получить API ключ на https://smith.langchain.com
# LANGSMITH_API_KEY=lsv2_pt_...
# LANGSMITH_TRACING_V2=true
# LANGSMITH_PROJECT=advanced-rag-assistant
# LANGSMITH_DATASET=06-rag-qa-dataset

# ============================================================
# SYSTEM PROMPT
# ============================================================

SYSTEM_PROMPT=Ты ассистент Сбербанка, отвечающий на вопросы по документам.
